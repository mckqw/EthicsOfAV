@article{Choi2013,
abstract = {In this paper, we present a general framework for tracking multiple, possibly interacting, people from a mobile vision platform. To determine all of the trajectories robustly and in a 3D coordinate system, we estimate both the camera's ego-motion and the people's paths within a single coherent framework. The tracking problem is framed as finding the MAP solution of a posterior probability, and is solved using the reversible jump Markov chain Monte Carlo (RJ-MCMC) particle filtering method. We evaluate our system on challenging datasets taken from moving cameras, including an outdoor street scene video dataset, as well as an indoor RGB-D dataset collected in an office. Experimental evidence shows that the proposed method can robustly estimate a camera's motion from dynamic scenes and stably track people who are moving independently or interacting.},
author = {Choi, Wongun and Pantofaru, Caroline and Savarese, Silvio},
doi = {10.1109/TPAMI.2012.248},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Multitarget tracking,RJ-MCMC particle filtering,people tracking,person detection},
number = {7},
pages = {1577--1591},
pmid = {23681988},
title = {{A general framework for tracking multiple people from a moving camera}},
volume = {35},
year = {2013}
}
@article{Ess2008,
abstract = {We present a mobile vision system for multi-person track- ing in busy environments. Specifically, the system integrates continuous visual odometry computation with tracking-by- detection in order to track pedestrians in spite of frequent occlusions and egomotion of the camera rig. To achieve re- liable performance under real-world conditions, it has long been advocated to extract and combine as much visual in- formation as possible. We propose a way to closely inte- grate the vision modules for visual odometry, pedestrian de- tection, depth estimation, and tracking. The integration nat- urally leads to several cognitive feedback loops between the modules. Among others, we propose a novel feedback con- nection from the object detector to visual odometry which utilizes the semantic knowledge of detection to stabilize lo- calization. Feedback loops always carry the danger that er- roneous feedback from one module is amplified and causes the entire system to become instable. We therefore incor- porate automatic failure detection and recovery, allowing the system to continue when a module becomes unreliable. The approach is experimentally evaluated on several long and difficult video sequences from busy inner-city locations. Our results show that the proposed integration makes it pos- sible to deliver stable tracking performance in scenes of previously infeasible complexity.},
author = {Ess, a. and Leibe, B. and Schindler, K. and {Van Gool}, L.},
doi = {10.1109/CVPR.2008.4587581},
isbn = {1424422426},
issn = {1063-6919},
journal = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
pages = {1--8},
title = {{A mobile vision system for robust multi-person tracking}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4587581},
year = {2008}
}
@inproceedings{Bansal2010,
abstract = {We present a real-time pedestrian detection system based on structure and appearance classification. We discuss several novel ideas that contribute to having low-false alarms and high detection rates, while at the same time achieving computational efficiency: (i) At the front end of our system we employ stereo to detect pedestrians in 3D range maps using template matching with a representative 3D shape model, and to classify other background objects in the scene such as buildings, trees and poles. The structure classification efficiently labels substantial amount of non-relevant image regions and guides the further computationally expensive process to focus on relatively small image parts; (ii)We improve the appearance-based classifiers based on HoG descriptors by performing template matching with 2D human shape contour fragments that results in improved localization and accuracy; (iii) We build a suite of classifiers tuned to specific distance ranges for optimized system performance. Our method is evaluated on publicly available datasets and is shown to match or exceed the performance of leading pedestrian detectors in terms of accuracy as well as achieving real-time computation (10 Hz), which makes it adequate for in-vehicle navigation platform.},
author = {Bansal, Mayank and Jung, Sang Hack and Matei, Bogdan and Eledath, Jayan and Sawhney, Harpreet},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2010.5509841},
isbn = {9781424450381},
issn = {10504729},
pages = {903--909},
title = {{A real-time pedestrian detection system based on structure and appearance classification}},
year = {2010}
}
@article{Dixit2016,
abstract = {Autonomous vehicles are being viewed with scepticism in their ability to improve safety and the driving experience. A critical issue with automated driving at this stage of its develop- ment is that it is not yet reliable and safe. When automated driving fails, or is limited, the autonomous mode disengages and the drivers are expected to resume manual driving. For this transition to occur safely, it is imperative that drivers react in an appropriate and timely manner. Recent data released from the California trials provide compelling insights into the current factors influencing disengagements of autonomous mode. Here we show that the number of accidents observed has a significantly high correlation with the autonomous miles travelled. The reaction times to take control of the vehicle in the event of a disengage- ment was found to have a stable distribution across different companies at 0.83 seconds on average. However, there were differences observed in reaction times based on the type of disengagements, type of roadway and autonomous miles travelled. Lack of trust caused by the exposure to automated disengagements was found to increase the likelihood to take control of the vehicle manually. Further, with increased vehicle miles travelled the reaction times were found to increase, which suggests an increased level of trust with more vehicle miles travelled.Webelieve that this research would provide insurers, planners, traffic man- agement officials and engineers fundamental insights into trust and reaction times that would help them design and engineer their systems.},
author = {Dixit, Vinayak V. and Chand, Sai and Nair, Divya J.},
doi = {10.1371/journal.pone.0168054},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
title = {{Autonomous vehicles: Disengagements, accidents and reaction times}},
volume = {11},
year = {2016}
}
@article{Dollar2014,
abstract = {Multi-resolution image features may be approximated via extrapolation from nearby scales, rather than being computed explicitly. This fundamental insight allows us to design object detection algorithms that are as accurate, and considerably faster, than the state-of-the-art. The computational bottleneck of many modern detectors is the computation of features at every scale of a finely- sampled image pyramid. Our key insight is that one may compute finely sampled feature pyramids at a fraction of the cost, without sacrificing performance: for a broad family of features we find that features computed at octave-spaced scale intervals are sufficient to approximate features on a finely-sampled pyramid. Extrapolation is inexpensive as compared to direct feature computation. As a result, our approximation yields considerable speedups with negligible loss in detection accuracy. We modify three diverse visual recognition systems to use fast feature pyramids and show results on both pedestrian detection (measured on the Caltech, INRIA, TUD-Brussels and ETH datasets) and general object detection (measured on the PASCAL VOC). The approach is general and is widely applicable to vision algorithms requiring fine-grained multi-scale analysis. Our approximation is valid for images with broad spectra (most natural images) and fails for images with narrow band-pass spectra (e.g. periodic textures). Index},
author = {Dollar, Piotr and Appel, Ron and Belongie, Serge and Perona, Pietro},
doi = {10.1109/TPAMI.2014.2300479},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Visual features,image pyramids,natural image statistics,object detection,pedestrian detection,real-time systems},
number = {8},
pages = {1532--1545},
pmid = {26353336},
title = {{Fast feature pyramids for object detection}},
volume = {36},
year = {2014}
}
@article{Garnett2007,
abstract = {This paper is devoted to the decomposition of an image f into u + v, with u a piecewise-smooth or "cartoon" component, and v an oscillatory component (texture or noise), in a variational approach. Y. Meyer [Y. Meyer, Oscillating Patterns in Image Processing and Nonlinear Evolution Equations, University Lecture Series, vol. 22, Amer. Math. Soc., Providence, RI, 2001] proposed refinements of the total variation model [L. Rudin, S. Osher, E. Fatemi, Nonlinear total variation based noise removal algorithms, Phys. D 60 (1992) 259-268] that better represent the oscillatory part v: the weaker spaces of generalized functions G = div (L∞), F = div (BMO), and E = over(B, ̇)∞, ∞-1 have been proposed to model v, instead of the standard L2 space, while keeping u ∈ BV, a function of bounded variation. Such new models separate better geometric structures from oscillatory structures, but it is difficult to realize them in practice. D. Mumford and B. Gidas [D. Mumford, B. Gidas, Stochastic models for generic images, Quart. Appl. Math. 59 (1) (2001) 85-111] also show that natural images can be seen as samples of scale invariant probability distributions that are supported on distributions only, and not on sets of functions. In this paper, we consider and generalize Meyer's (BV, E) model, using the homogeneous Besov spaces over(B, ̇)p, q$\alpha$, - 2 {\textless} $\alpha$ {\textless} 0, 1 ≤ p, q ≤ ∞, to represent the oscillatory part v. Theoretical, experimental results and comparisons to validate the proposed methods are presented. {\textcopyright} 2007.},
author = {Garnett, John B. and Le, Triet M. and Meyer, Yves and Vese, Luminita A.},
doi = {10.1016/j.acha.2007.01.005},
issn = {10635203},
journal = {Applied and Computational Harmonic Analysis},
number = {1},
pages = {25--56},
title = {{Image decompositions using bounded variation and generalized homogeneous Besov spaces}},
volume = {23},
year = {2007}
}
@article{An2016,
abstract = {There are several types of intersections such as merge-roads, diverge-roads, plus-shape intersections and two types of T-shape junctions in urban roads. When an autonomous vehicle encounters new intersections, it is crucial to recognize the types of intersections for safe navigation. In this paper, a novel intersection type recognition method is proposed for an autonomous vehicle using a multi-layer laser scanner. The proposed method consists of two steps: (1) static local coordinate occupancy grid map (SLOGM) building and (2) intersection classification. In the first step, the SLOGM is built relative to the local coordinate using the dynamic binary Bayes filter. In the second step, the SLOGM is used as an attribute for the classification. The proposed method is applied to a real-world environment and its validity is demonstrated through experimentation.},
author = {An, Jhonghyun and Choi, Baehoon and Sim, Kwee Bo and Kim, Euntai},
doi = {10.3390/s16071123},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Intersections,Local coordinate,Multi-laser scanner,Occupancy grid map,Recognition,Static map},
number = {7},
title = {{Novel intersection type recognition for autonomous vehicles using a multi-layer laser scanner}},
volume = {16},
year = {2016}
}
@article{Gao2015,
abstract = {Multipedestrian tracking in traffic scenes is challenging due to cluttered backgrounds and serious occlusions. In this paper, we propose a layered graph model in image (RGB) and depth (D) domains for real-time robust multipedestrian tracking. The motivation is to investigate high-level constraints in RGB-D data association and to improve the optimization from the trajectory level to the layer level. To construct a layered graph, we define constraints in the depth domain so that pedestrian objects in the image domain are assigned to proper layers. We use pedestrian detection responses in the RGB domain as graph nodes, and we integrate 3-D motion, appearance, and depth features as graph edges. An online updating depth factor is defined to describe the depth relationships among the observations in and out of the layers, and the occlusion issue is processed with an analytical layer-level strategy. With a heuristic label switching algorithm, multiple pedestrian objects are optimally associated and tracked. Experiments and comparison on five public data sets show that our proposed approach significantly reduces pedestrian's ID switch and improves tracking accuracy in the cases of serious occlusions.},
author = {Gao, Shan and Han, Zhenjun and Li, Ce and Ye, Qixiang and Jiao, Jianbin},
doi = {10.1109/TITS.2015.2423709},
isbn = {1524-9050},
issn = {15249050},
journal = {IEEE Transactions on Intelligent Transportation Systems},
keywords = {Multi-pedestrian tracking,RGB-D data,layered graph model,occlusion},
number = {5},
pages = {2814--2825},
title = {{Real-Time Multipedestrian Tracking in Traffic Scenes via an RGB-D-Based Layered Graph Model}},
volume = {16},
year = {2015}
}
@article{Vondrick2016,
abstract = {We introduce algorithms to visualize feature spaces used by object detectors. The tools in this paper allow a human to put on ‘HOG goggles' and perceive the visual world as a HOG based object detector sees it. We found that these visualizations allow us to analyze object detection systems in new ways and gain new insight into the detector's fail- ures. For example, when we visualize the features for high scoring false alarms, we discovered that, although they are clearly wrong in image space, they do look deceptively sim- ilar to true positives in feature space. This result suggests that many of these false alarms are caused by our choice of feature space, and indicates that creating a better learning algorithm or building bigger datasets is unlikely to correct these errors. By visualizing feature spaces, we can gain a more intuitive understanding of our detection systems.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.05461v1},
author = {Vondrick, Carl and Khosla, Aditya and Pirsiavash, Hamed and Malisiewicz, Tomasz and Torralba, Antonio},
doi = {10.1007/s11263-016-0884-7},
eprint = {arXiv:1502.05461v1},
isbn = {9781479928392},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Feature visualization,Object detection,Visual recognition},
number = {2},
pages = {145--158},
title = {{Visualizing Object Detection Features}},
volume = {119},
year = {2016}
}
@inproceedings{Dalal2005,
abstract = {We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
archivePrefix = {arXiv},
arxivId = {chao-dyn/9411012},
author = {Dalal, N. and Triggs, B.},
booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
doi = {10.1109/CVPR.2005.177},
eprint = {9411012},
isbn = {0-7695-2372-2},
issn = {1063-6919},
pages = {886--893},
pmid = {9230594},
primaryClass = {chao-dyn},
title = {{Histograms of Oriented Gradients for Human Detection}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp={\&}arnumber=1467360{\&}contentType=Conference+Publications{\&}searchField=Search{\_}All{\&}queryText=Histograms+of+oriented+gradients+for+human+detection},
volume = {1},
year = {2005}
}
